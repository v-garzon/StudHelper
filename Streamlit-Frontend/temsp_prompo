now lets work on the second phase. create the full backend for the streamlit frontend. 
follow this folder structure for maximising scalability and fast testing:
StudHelper-Streamlit/                    # ğŸ“ Root project directory
â”œâ”€â”€ ğŸ“„ main.py                         # ğŸ”„ UPDATED - Main Streamlit app with real backend integration
â”œâ”€â”€ ğŸ“„ .env                            # ğŸ†• NEW - Environment variables (OpenAI API key, etc.)
â”œâ”€â”€ ğŸ“„ .env.template                   # ğŸ†• NEW - Environment template for setup
â”œâ”€â”€ ğŸ“„ requirements.txt                # ğŸ”„ UPDATED - All real dependencies (no more placeholders)
â”œâ”€â”€ ğŸ“„ README.md                       # ğŸ”„ UPDATED - Complete setup and usage guide
â”œâ”€â”€ ğŸ“„ .gitignore                      # âœ… EXISTING - Git ignore rules
â”œâ”€â”€ ğŸ“„ setup_folders.sh                # âœ… EXISTING - Folder setup script
â”‚
â”œâ”€â”€ ğŸ“ components/                     # ğŸ–¥ï¸ FRONTEND COMPONENTS
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py                 # âœ… EXISTING - Package marker
â”‚   â”œâ”€â”€ ğŸ“„ sidebar.py                  # âœ… EXISTING - Class management sidebar
â”‚   â”œâ”€â”€ ğŸ“„ welcome.py                  # âœ… EXISTING - Welcome/landing page
â”‚   â”œâ”€â”€ ğŸ“„ knowledge_upload.py         # ğŸ”„ UPDATED - Real file processing integration
â”‚   â””â”€â”€ ğŸ“„ chat_interface.py           # ğŸ”„ UPDATED - Real AI chat with 3 modes
â”‚
â”œâ”€â”€ ğŸ“ utils/                          # âš™ï¸ BACKEND UTILITIES
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py                 # âœ… EXISTING - Package marker
â”‚   â”œâ”€â”€ ğŸ“„ session_state.py            # ğŸ”„ UPDATED - Enhanced state management
â”‚   â”œâ”€â”€ ğŸ“„ file_processing.py          # ğŸ”„ UPDATED - REAL file processing (no placeholders)
â”‚   â”œâ”€â”€ ğŸ“„ youtube_handler.py          # ğŸ”„ UPDATED - REAL Whisper transcription
â”‚   â”œâ”€â”€ ğŸ“„ openai_handler.py           # ğŸ†• NEW - OpenAI API integration & cost tracking
â”‚   â””â”€â”€ ğŸ“„ vector_database.py          # ğŸ†• NEW - ChromaDB vector database management
â”‚
â”œâ”€â”€ ğŸ“ storage/                        # ğŸ’¾ DATA STORAGE
â”‚   â”œâ”€â”€ ğŸ“ uploads/                    # ğŸ“„ Document uploads
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ .gitkeep                # âœ… EXISTING - Keep empty folder in git
â”‚   â”‚   â””â”€â”€ ğŸ“„ [uploaded_files]        # ğŸ”„ DYNAMIC - User uploaded documents
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ vectors/                    # ğŸ”¢ Vector database
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ .gitkeep                # âœ… EXISTING - Keep empty folder in git
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ chroma.sqlite3          # ğŸ”„ DYNAMIC - ChromaDB database file
â”‚   â”‚   â””â”€â”€ ğŸ“ [class_collections]/    # ğŸ”„ DYNAMIC - Per-class vector collections
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ temp/                       # ğŸ†• NEW - Temporary files (auto-created)
â”‚       â””â”€â”€ ğŸ“ audio/                  # ğŸ”„ DYNAMIC - YouTube audio downloads
â”‚
â”œâ”€â”€ ğŸ“ docs/                           # ğŸ“š DOCUMENTATION
â”‚   â”œâ”€â”€ ğŸ“„ setup_guide.md              # ğŸ†• NEW - Complete setup instructions
â”‚   â”œâ”€â”€ ğŸ“„ architecture.md             # ğŸ†• NEW - System architecture docs
â”‚   â”œâ”€â”€ ğŸ“„ performance_upgrades.md     # ğŸ†• NEW - Optimization recommendations
â”‚   â””â”€â”€ ğŸ“„ cost_analysis.md            # ğŸ†• NEW - Cost tracking and estimates
â”‚
â”œâ”€â”€ ğŸ“ tests/                          # ğŸ§ª TESTING (Future Phase)
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py                 # ğŸ“‹ PLANNED - Test package marker
â”‚   â”œâ”€â”€ ğŸ“„ test_file_processing.py     # ğŸ“‹ PLANNED - File processing tests
â”‚   â”œâ”€â”€ ğŸ“„ test_openai_handler.py      # ğŸ“‹ PLANNED - OpenAI integration tests
â”‚   â”œâ”€â”€ ğŸ“„ test_vector_database.py     # ğŸ“‹ PLANNED - Vector DB tests
â”‚   â””â”€â”€ ğŸ“„ test_youtube_handler.py     # ğŸ“‹ PLANNED - YouTube processing tests
â”‚
â”œâ”€â”€ ğŸ“ config/                         # âš™ï¸ CONFIGURATION (Future Phase)
â”‚   â”œâ”€â”€ ğŸ“„ prompts.yaml                # ğŸ“‹ PLANNED - System prompt templates
â”‚   â”œâ”€â”€ ğŸ“„ models.yaml                 # ğŸ“‹ PLANNED - Model configurations
â”‚   â””â”€â”€ ğŸ“„ costs.yaml                  # ğŸ“‹ PLANNED - Cost rate configurations
â”‚
â””â”€â”€ ğŸ“ logs/                           # ğŸ“Š LOGGING (Future Phase)
    â”œâ”€â”€ ğŸ“„ app.log                     # ğŸ“‹ PLANNED - Application logs
    â”œâ”€â”€ ğŸ“„ costs.log                   # ğŸ“‹ PLANNED - Cost tracking logs
    â””â”€â”€ ğŸ“„ errors.log                  # ğŸ“‹ PLANNED - Error logs

# ğŸ“Š DETAILED FILE BREAKDOWN

## ğŸ”„ UPDATED FILES (Enhanced with real backend)

### ğŸ“„ main.py
- Real environment checking
- OpenAI API key validation  
- System status monitoring
- Cost tracking display
- Real backend integration

### ğŸ“ components/
â”œâ”€â”€ ğŸ“„ knowledge_upload.py
â”‚   - Real file validation
â”‚   - Actual processing progress
â”‚   - Vector database integration
â”‚   - Real cost estimation
â”‚
â””â”€â”€ ğŸ“„ chat_interface.py
    - 3 real AI modes (Economic/Standard/Turbo)
    - Real OpenAI API calls
    - Vector similarity search
    - Cost tracking per message
    - Source attribution from documents

### ğŸ“ utils/
â”œâ”€â”€ ğŸ“„ file_processing.py
â”‚   - REAL PDF processing (PyPDF2, pdfplumber)
â”‚   - REAL Word processing (python-docx)
â”‚   - REAL PowerPoint processing (python-pptx)
â”‚   - Smart chunking algorithms
â”‚   - Error handling & validation
â”‚
â”œâ”€â”€ ğŸ“„ youtube_handler.py
â”‚   - REAL audio download (yt-dlp)
â”‚   - REAL transcription (Whisper)
â”‚   - Video info extraction
â”‚   - Cost estimation
â”‚   - Multiple quality levels
â”‚
â””â”€â”€ ğŸ“„ session_state.py
    - Enhanced class management
    - Vector database integration
    - Cost tracking state
    - Debug utilities

## ğŸ†• NEW FILES (Phase 2 Backend)

### ğŸ“„ utils/openai_handler.py
- OpenAI API client setup
- Chat completions with 3 modes:
  * Economic: gpt-4o-mini ($0.15/$0.60 per 1M tokens)
  * Standard: gpt-4o ($2.50/$10.00 per 1M tokens)  
  * Turbo: gpt-4o + Chain of Thought
- Embeddings generation (text-embedding-3-small/large)
- Real-time token counting
- Cost tracking and limits
- Error handling & retries

### ğŸ“„ utils/vector_database.py
- ChromaDB client management
- Per-class collections
- Document embedding storage
- Similarity search with metadata
- Context retrieval for chat
- Collection statistics
- Database health monitoring

### ğŸ“„ .env / .env.template
- OpenAI API key configuration
- Storage path settings
- Processing parameters
- Cost control limits
- Model configurations

### ğŸ“„ requirements.txt (UPDATED)
- All real dependencies
- OpenAI API client
- ChromaDB vector database
- Document processing libraries
- YouTube processing tools
- Audio transcription (Whisper)

## ğŸ“‹ PROCESSING FLOW

### ğŸ“„ Document Processing Path:
1. components/knowledge_upload.py â†’ User uploads file
2. utils/file_processing.py â†’ Extract text (PDF/Word/PowerPoint)
3. utils/file_processing.py â†’ Create chunks with overlap
4. utils/openai_handler.py â†’ Generate embeddings
5. utils/vector_database.py â†’ Store in ChromaDB
6. storage/vectors/ â†’ Persistent vector storage

### ğŸ¥ YouTube Processing Path:
1. components/knowledge_upload.py â†’ User enters URL
2. utils/youtube_handler.py â†’ Validate & get video info
3. utils/youtube_handler.py â†’ Download audio (yt-dlp)
4. utils/youtube_handler.py â†’ Transcribe with Whisper
5. utils/openai_handler.py â†’ Generate embeddings
6. utils/vector_database.py â†’ Store transcript chunks

### ğŸ’¬ Chat Processing Path:
1. components/chat_interface.py â†’ User asks question
2. utils/vector_database.py â†’ Search for relevant chunks
3. utils/vector_database.py â†’ Retrieve context
4. utils/openai_handler.py â†’ Create prompt + context
5. utils/openai_handler.py â†’ Call OpenAI API
6. utils/openai_handler.py â†’ Track tokens & cost
7. components/chat_interface.py â†’ Display response + sources

## ğŸ”§ SETUP REQUIREMENTS

### System Dependencies:
- Python 3.8+ with pip
- FFmpeg (for YouTube audio processing)
- 4GB+ RAM (for Whisper models)
- OpenAI API key with credits

### Python Packages (automatically installed):
- streamlit, openai, chromadb
- PyPDF2, pdfplumber, python-docx, python-pptx
- whisper, yt-dlp, torch
- tiktoken, numpy, pandas

### Storage Requirements:
- ~1GB for Whisper models (auto-downloaded)
- ~100MB for ChromaDB per class
- Variable space for uploaded documents

## ğŸ¯ PHASE 2 COMPLETION STATUS

âœ… COMPLETE: Real backend implementation
âœ… COMPLETE: 3-mode AI chat system  
âœ… COMPLETE: Document & YouTube processing
âœ… COMPLETE: Vector database integration
âœ… COMPLETE: Cost tracking & monitoring
âœ… COMPLETE: Modular architecture
âœ… COMPLETE: Ready for production testing

## ğŸ“ˆ READY FOR PHASE 3 (Future)
- Advanced prompt engineering
- Response caching system
- Performance optimizations
- Multi-user support
- Cloud deployment options
Content is user-generated and unverified.
 

for costs traking leave it as only tracking how many tokens per model have you used and then multiply it by the price per M tokens of that model. in the future we will use the Usage API (beta) from openai.

with this phase finished I have to be able to:
1. create classes.
2. add knowledge. real file/YouTube link processing
3. select one of the 3 different methods for chatting
4. chat freely. 'freely' but it has to be real, no placeholders






create 3 modes for chatting:
economic: using models with the mini version to reduce costs to max (gpt-mini)
standart: standart computing costs and standard performance (gpt)
turbo: best models, chain of thought available. prioritise performance before costs (gpt-turbo)


also tell me potential upgrades in the code you are going to create. ej. upgrade prompts, migrate to other libraries, â€¦ where you really think it is important to double check for potential losses of performance